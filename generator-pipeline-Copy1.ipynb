{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import models.finalModels as finalModels\n",
    "import keras.applications as kap\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import h5py\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import pickle\n",
    "\n",
    "import utils\n",
    "import preprocessing as pp\n",
    "pp.init()\n",
    "\n",
    "allTrainingFolders = [x for x in os.listdir(pp.trainPath) if x.startswith('n')]\n",
    "np.random.shuffle(allTrainingFolders)\n",
    "num = 25\n",
    "trainingFolders = allTrainingFolders[0:num]\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp.trainPath = 'E:\\\\SCHOOL CMPS 240\\\\ILSVRC\\Data\\\\CLS-LOC\\\\train'\n",
    "\n",
    "# allTrainingFolders = [x for x in os.listdir(pp.trainPath) if x.startswith('n')]\n",
    "# np.random.shuffle(allTrainingFolders)\n",
    "# num = 25\n",
    "# trainingFolders = allTrainingFolders[0:num]\n",
    "\n",
    "# trainingFolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open (os.path.join('output', 'trainingFolderOrder25.text'), 'rb') as fp:     \n",
    "#     trainingFolders = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse =False\n",
    "train = True\n",
    "saveModel = False\n",
    "includeAugmented = False\n",
    "onlyAugmented = False\n",
    "\n",
    "augments = [iaa.Rot90(1), iaa.Rot90(2), iaa.Fliplr(1), iaa.Flipud(1), iaa.Noop(), iaa.Dropout((0.01, 0.1), per_channel=0.5), \n",
    "            iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5), iaa.PerspectiveTransform(scale=(0.01, 0.1))]\n",
    "# augments = []\n",
    "h5filename = '{0}-finalclasses.h5'.format(num)\n",
    "h5file = os.path.join(pp.h5Path, h5filename)\n",
    "\n",
    "if parse:\n",
    "    if os.path.isfile(os.path.join(pp.h5Path, h5filename)):\n",
    "        os.remove(os.path.join(pp.h5Path, h5filename))\n",
    "    pp.parseImages(trainingFolders, h5filename)\n",
    "#     pp.shuffleH5(h5file)\n",
    "    #write to text file\n",
    "    with open(os.path.join('output', 'trainingFolderOrder25.text'), 'wb') as fp:     \n",
    "        pickle.dump(trainingFolders, fp)\n",
    "    \n",
    "#read back    \n",
    "with open (os.path.join('output', 'trainingFolderOrder25.text'), 'rb') as fp:     \n",
    "    trainingFolders = pickle.load(fp)\n",
    "    \n",
    "encoder = LabelBinarizer()\n",
    "##MAKE SURE classLabels is set to ALL the folders you will train on, even if doing in batches\n",
    "encoder = encoder.fit(trainingFolders)\n",
    "\n",
    "h5db = h5py.File(h5file, 'r')\n",
    "\n",
    "x_val = h5db['x_val'][:]\n",
    "y_val = h5db['y_val'][:]\n",
    "\n",
    "y_val = [k.decode('utf-8') for k in y_val]\n",
    "\n",
    "y_val = encoder.transform(y_val)\n",
    "val_data = (np.array(x_val), np.array(y_val))\n",
    "\n",
    "h5db.close()\n",
    "    \n",
    "#NOTE: KEEP BATCH SIZE = # of all folders for now because we need to shuffle H5. \n",
    "\n",
    "filepath=os.path.join(pp.outputModelPath, \"best-epoch-finalmodel-{epoch:02d}-{val_acc:.2f}.hdf5\")\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                   patience=20, min_delta=0.5)\n",
    "# tb = keras.callbacks.TensorBoard(log_dir='./tensor-graph', histogram_freq=0,             \n",
    "#                                  write_graph=False, write_images=False)\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "epochs = 100\n",
    "sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# adam = keras.optimizers.Adam(lr=0.01, decay=1e-6)\n",
    "model = finalModels.finalModel(len(encoder.classes_)) \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# model = load_model((os.path.join(pp.outputModelPath, 'best-epoch-finalModel-37-0.68.hdf5')))\n",
    "\n",
    "y_ints = [y.argmax() for y in y_val] \n",
    "class_weights = class_weight.compute_class_weight('balanced',                                                  \n",
    "                                                np.unique(y_ints),                                                  \n",
    "                                                y_ints)\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "##FIT MODEL\n",
    "if train:\n",
    "    train_generator = pp.DataGenerator3(h5file, trainingFolders, batch_size=batch_size, augmentations = augments, augmentReplace = False\n",
    "                                       , augment_pct = 0.25, shuffle=True)\n",
    "    val_generator = pp.DataGenerator3(h5file, trainingFolders, batch_size=batch_size, isValidation = True)\n",
    "    print(len(train_generator))\n",
    "    results = model.fit_generator(train_generator, validation_data = val_data, epochs=epochs, callbacks = callbacks, verbose=1,\n",
    "                              use_multiprocessing=True, workers=4, class_weight = class_weights)\n",
    "    with open(os.path.join(pp.trainhistory, 'finalmodelhistory.pkl'), 'wb') as file_pi:         \n",
    "        pickle.dump(results.history, file_pi)\n",
    "\n",
    "    if saveModel:\n",
    "        count = 1\n",
    "        outputName = \"\"\n",
    "        while True:\n",
    "            k = ''\n",
    "            if includeAugmented:\n",
    "                k = 'with-aug'\n",
    "            if onlyAugmented:\n",
    "                k = 'aug-only'\n",
    "            s = pp.baseModelName.format(epoch, count, k) + \".h5\" \n",
    "            if not s in os.listdir(pp.outputModelPath):         \n",
    "                outputName = s         \n",
    "                break     \n",
    "            else:         \n",
    "                count+=1 \n",
    "        print(outputName)\n",
    "        model.save(os.path.join(pp.outputModelPath, outputName))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(pp.trainhistory, 'finalmodelhistory.pkl'), 'wb') as file_pi:         \n",
    "        pickle.dump(results.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (os.path.join(pp.trainhistory, 'finalmodelhistory.pkl'), 'rb') as fp:     \n",
    "    results = pickle.load(fp)\n",
    "    print(results['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing as pp\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "h5filename = '25-finalclasses.h5'\n",
    "h5file = os.path.join(pp.h5Path, h5filename)\n",
    "h5db = h5py.File(h5file, 'r') \n",
    "print(len(h5db['x_train']))\n",
    "h5db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = load_model((os.path.join(pp.outputModelPath, 'best-epoch-Res25-100-0.63.hdf5')))\n",
    "model1 = load_model((os.path.join(pp.outputModelPath, 'best-epoch-RESNET50-37-0.53.hdf5')))\n",
    "model2 = load_model((os.path.join(pp.outputModelPath, 'best-epoch-SSD7-30-0.61.hdf5')))\n",
    "model3 = load_model((os.path.join(pp.outputModelPath, 'best-epoch-finalmodel-99-0.66.hdf5')))\n",
    "\n",
    "# model.history\n",
    "h5filename = '{0}-finalclasses.h5'.format(num)\n",
    "h5file = os.path.join(pp.h5Path, h5filename)\n",
    "\n",
    "h5db = h5py.File(h5file, 'r')\n",
    "print(\"ResNet50 top 5: \", pp.top5accuracies(model1, h5db['x_val'][:], h5db['y_val'][:], encoder))\n",
    "print(\"SSD7 top 5: \", pp.top5accuracies(model2, h5db['x_val'][:], h5db['y_val'][:], encoder))\n",
    "print(\"Final Model top 5: \", pp.top5accuracies(model3, h5db['x_val'][:], h5db['y_val'][:], encoder))\n",
    "# # df = pp.predictionsToDataframe(model, h5db['x_val'][:], h5db['y_val'][:], encoder)\n",
    "# # df[700:1100]\n",
    "h5db.close()\n",
    "\n",
    "\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resNet = None\n",
    "ssd = None\n",
    "FinalNet = None\n",
    "FinalNetaugs = None\n",
    "with open (os.path.join(pp.trainhistory, 'Reshistory.pkl'), 'rb') as fp:     \n",
    "    resNet = pickle.load(fp)\n",
    "with open (os.path.join(pp.trainhistory, 'SSDhistory.pkl'), 'rb') as fp2:     \n",
    "     ssd = pickle.load(fp2)\n",
    "with open (os.path.join(pp.trainhistory, 'finalmodelhistory.pkl'), 'rb') as fp3:     \n",
    "     FinalNet = pickle.load(fp3)\n",
    "with open (os.path.join(pp.trainhistory, 'finalmodelAUGShistory.pkl'), 'rb') as fp4:     \n",
    "     FinalNetaugs = pickle.load(fp4)\n",
    "    \n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "x = np.arange(epochs)+1\n",
    "plt.plot(x, resNet['acc'], color = 'red')\n",
    "plt.plot(x, resNet['val_acc'], color = 'orange')\n",
    "# plt.xticks(x)\n",
    "# plt.xticks([10*i for i in range(0, 11)])\n",
    "plt.title('ResNet50 Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.yticks([0.1*i for i in range(0, 11)])\n",
    "# plt.ylim(0.5, 1.0)\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train - ResNet', 'Val - ResNet'], loc='upper left')\n",
    "# plt.savefig(os.path.join('output', 'figs', outputName+'-accuracy.png'))\n",
    "plt.show()\n",
    "\n",
    "x = np.arange(epochs)+1\n",
    "plt.plot(x, ssd['acc'], color = 'brown')\n",
    "plt.plot(x, ssd['val_acc'], color = 'green')\n",
    "# plt.xticks(x)\n",
    "# plt.xticks([10*i for i in range(0, 11)])\n",
    "plt.title('SSD7 Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.yticks([0.1*i for i in range(0, 11)])\n",
    "# plt.ylim(0.5, 1.0)\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train - SSD', 'Val - SSD'], loc='upper left')\n",
    "# plt.savefig(os.path.join('output', 'figs', outputName+'-accuracy.png'))\n",
    "plt.show()\n",
    "\n",
    "x = np.arange(epochs)+1\n",
    "plt.plot(x, FinalNet['acc'], color = 'blue')\n",
    "plt.plot(x, FinalNet['val_acc'], color = 'purple')\n",
    "# plt.xticks(x)\n",
    "# plt.xticks([10*i for i in range(0, 11)])\n",
    "plt.yticks([0.1*i for i in range(0, 11)])\n",
    "plt.title('Final Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.ylim(0.5, 1.0)\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train - FinalNet', 'Val - FinalNet'], loc='upper left')\n",
    "# plt.savefig(os.path.join('output', 'figs', outputName+'-accuracy.png'))\n",
    "plt.show()\n",
    "\n",
    "x = np.arange(epochs)+1\n",
    "plt.plot(x, FinalNetaugs['acc'], color = 'black')\n",
    "plt.plot(x, FinalNetaugs['val_acc'], color = 'gray')\n",
    "# plt.xticks(x)\n",
    "# plt.xticks([10*i for i in range(0, 11)])\n",
    "plt.yticks([0.1*i for i in range(0, 11)])\n",
    "plt.title('Final Model w/ Augs Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.ylim(0.5, 1.0)\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train - FinalNetAugs', 'Val - FinalNetAugs'], loc='upper left')\n",
    "# plt.savefig(os.path.join('output', 'figs', outputName+'-accuracy.png'))\n",
    "plt.show()\n",
    "\n",
    "# # Plot training & validation loss values\n",
    "# plt.plot(x, resNet['loss'])\n",
    "# plt.plot(x, resNet['val_loss'])\n",
    "# plt.plot(x, ssd['loss'])\n",
    "# plt.plot(x, ssd['val_loss'])\n",
    "# plt.plot(x, SwagNet['loss'])\n",
    "# plt.plot(x, SwagNet['val_loss'])\n",
    "# # plt.xticks(x)\n",
    "# # plt.xticks([10*i for i in range(0, 11)])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# # plt.ylim(0, 0.7)\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Val'], loc='upper left')\n",
    "# # plt.savefig(os.path.join('output', 'figs', outputName+'-loss.png'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

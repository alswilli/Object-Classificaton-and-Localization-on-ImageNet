{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking to make sure output directories are created..\n",
      "..done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import models.simpleConv as simpleConv\n",
    "import models.crazyNet as crazyNet\n",
    "import models.newModel as newModel\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "# import models.betterConv as betterConv\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import h5py\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import pickle\n",
    "\n",
    "import utils\n",
    "import preprocessing as pp\n",
    "pp.init()\n",
    "\n",
    "allTrainingFolders = [x for x in os.listdir(pp.trainPath) if x.startswith('n')]\n",
    "np.random.shuffle(allTrainingFolders)\n",
    "num = 50\n",
    "trainingFolders = allTrainingFolders[0:num]\n",
    "\n",
    "# with open('trainingFolderOrder.text', 'w') as f:\n",
    "#     f.write(\" \".join(trainingFolders))\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n03179701',\n",
       " 'n01980166',\n",
       " 'n02268443',\n",
       " 'n02108915',\n",
       " 'n02865351',\n",
       " 'n09428293',\n",
       " 'n02895154',\n",
       " 'n02825657',\n",
       " 'n01608432',\n",
       " 'n02782093']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.trainPath = 'E:\\\\SCHOOL CMPS 240\\\\ILSVRC\\Data\\\\CLS-LOC\\\\train'\n",
    "\n",
    "allTrainingFolders = [x for x in os.listdir(pp.trainPath) if x.startswith('n')]\n",
    "np.random.shuffle(allTrainingFolders)\n",
    "num = 10\n",
    "trainingFolders = allTrainingFolders[0:num]\n",
    "\n",
    "trainingFolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turnstile n04501370\n",
      "potter's wheel n03992509\n",
      "cassette player n02979186\n",
      "flat-coated retriever n02099267\n",
      "axolotl, mud puppy, Ambystoma mexicanum n01632777\n",
      "triceratops n01704323\n",
      "cabbage butterfly n02280649\n",
      "drake n01847000\n",
      "bullet train, bullet n02917067\n",
      "Kerry blue terrier n02093859\n",
      "wok n04596742\n",
      "schipperke n02104365\n",
      "bobsled, bobsleigh, bob n02860847\n",
      "apiary, bee house n02727426\n",
      "marmoset n02490219\n",
      "amphibian, amphibious vehicle n02704792\n",
      "beaver n02363005\n",
      "hay n07802026\n",
      "giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca n02510455\n",
      "racket, racquet n04039381\n",
      "sidewinder, horned rattlesnake, Crotalus cerastes n01756291\n",
      "projectile, missile n04008634\n",
      "gong, tam-tam n03447721\n",
      "sports car, sport car n04285008\n",
      "jeep, landrover n03594945\n",
      "pitcher, ewer n03950228\n",
      "china cabinet, china closet n03018349\n",
      "soup bowl n04263257\n",
      "German short-haired pointer n02100236\n",
      "American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier n02093428\n",
      "lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens n02509815\n",
      "dial telephone, dial phone n03187595\n",
      "tractor n04465501\n",
      "red wine n07892512\n",
      "cliff, drop, drop-off n09246464\n",
      "mud turtle n01667114\n",
      "porcupine, hedgehog n02346627\n",
      "vacuum, vacuum cleaner n04517823\n",
      "liner, ocean liner n03673027\n",
      "loggerhead, loggerhead turtle, Caretta caretta n01664065\n",
      "water ouzel, dipper n01601694\n",
      "worm fence, snake fence, snake-rail fence, Virginia fence n04604644\n",
      "mailbag, postbag n03709823\n",
      "brain coral n01917289\n",
      "velvet n04525038\n",
      "dough n07860988\n",
      "table lamp n04380533\n",
      "pajama, pyjama, pj's, jammies n03877472\n",
      "leopard, Panthera pardus n02128385\n",
      "Band Aid n02786058\n"
     ]
    }
   ],
   "source": [
    "arr =[pp.translateID(x) for x in trainingFolders]\n",
    "\n",
    "for x, y in zip(arr, trainingFolders):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "parse = False\n",
    "train = True\n",
    "saveModel = False\n",
    "includeAugmented = False\n",
    "onlyAugmented = False\n",
    "\n",
    "augments = [iaa.GaussianBlur(3.0)]\n",
    "h5filename = '{0}-RANDcrazy.h5'.format(num)\n",
    "h5file = os.path.join(pp.h5Path, h5filename)\n",
    "\n",
    "if parse:\n",
    "    if os.path.isfile(os.path.join(pp.h5Path, h5filename)):\n",
    "        os.remove(os.path.join(pp.h5Path, h5filename))\n",
    "    pp.parseImages(trainingFolders, h5filename)\n",
    "#     pp.shuffleH5(h5file)\n",
    "    #write to text file\n",
    "    with open(os.path.join('output', 'trainingFolderOrder.text'), 'wb') as fp:     \n",
    "        pickle.dump(trainingFolders, fp)\n",
    "    \n",
    "#read back    \n",
    "with open (os.path.join('output', 'trainingFolderOrder.text'), 'rb') as fp:     \n",
    "    trainingFolders = pickle.load(fp)\n",
    "    \n",
    "encoder = LabelBinarizer()\n",
    "##MAKE SURE classLabels is set to ALL the folders you will train on, even if doing in batches\n",
    "encoder = encoder.fit(trainingFolders)\n",
    "    \n",
    "#NOTE: KEEP BATCH SIZE = # of all folders for now because we need to shuffle H5. \n",
    "\n",
    "\n",
    "filepath=os.path.join(pp.outputModelPath, \"best-epoch-CrazyEditedw50-{epoch:02d}-{val_acc:.2f}.hdf5\")\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "epochs = 100\n",
    "sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# adam = keras.optimizers.Adam(lr=0.01, decay=1e-6)\n",
    "model = crazyNet.build_model3(len(encoder.classes_))\n",
    "# model = ResNet50(weights=None, include_top ='True', classes=50) \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# model = load_model((os.path.join(pp.outputModelPath, 'CrazyNet5Epoch50Class.h5')))\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "##FIT MODEL\n",
    "if train:\n",
    "    train_generator = pp.DataGenerator3(h5file, trainingFolders, batch_size=batch_size)\n",
    "    val_generator = pp.DataGenerator3(h5file, trainingFolders, batch_size=batch_size, isValidation = True)\n",
    "    print(len(train_generator))\n",
    "    results = model.fit_generator(train_generator, validation_data = val_generator, epochs=epochs, callbacks = callbacks, verbose=1,\n",
    "                              use_multiprocessing=True, workers=4)\n",
    "\n",
    "    if saveModel:\n",
    "        count = 1\n",
    "        outputName = \"\"\n",
    "        while True:\n",
    "            k = ''\n",
    "            if includeAugmented:\n",
    "                k = 'with-aug'\n",
    "            if onlyAugmented:\n",
    "                k = 'aug-only'\n",
    "            s = pp.baseModelName.format(epoch, count, k) + \".h5\" \n",
    "            if not s in os.listdir(pp.outputModelPath):         \n",
    "                outputName = s         \n",
    "                break     \n",
    "            else:         \n",
    "                count+=1 \n",
    "        print(outputName)\n",
    "        model.save(os.path.join(pp.outputModelPath, outputName))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5db = h5py.File(h5file, 'r') \n",
    "h5db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output\\\\image-h5\\\\50-RANDcrazy.h5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.shuffleH5(h5file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vine snake',\n",
       " 'triceratops',\n",
       " 'quail',\n",
       " 'tiger shark, Galeocerdo cuvieri',\n",
       " 'common newt, Triturus vulgaris',\n",
       " 'house finch, linnet, Carpodacus mexicanus',\n",
       " 'diamondback, diamondback rattlesnake, Crotalus adamanteus',\n",
       " 'prairie chicken, prairie grouse, prairie fowl',\n",
       " 'hornbill',\n",
       " 'alligator lizard',\n",
       " 'trilobite',\n",
       " 'frilled lizard, Chlamydosaurus kingi',\n",
       " 'Indian cobra, Naja naja',\n",
       " 'chickadee',\n",
       " 'magpie',\n",
       " 'electric ray, crampfish, numbfish, torpedo',\n",
       " 'goldfish, Carassius auratus',\n",
       " 'horned viper, cerastes, sand viper, horned asp, Cerastes cornutus',\n",
       " 'hen',\n",
       " 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',\n",
       " 'bulbul',\n",
       " 'terrapin',\n",
       " 'black grouse',\n",
       " 'black swan, Cygnus atratus',\n",
       " 'hummingbird',\n",
       " 'water ouzel, dipper',\n",
       " 'ringneck snake, ring-necked snake, ring snake',\n",
       " 'water snake',\n",
       " 'African chameleon, Chamaeleo chamaeleon',\n",
       " 'jay',\n",
       " 'black widow, Latrodectus mactans',\n",
       " 'night snake, Hypsiglena torquata',\n",
       " 'axolotl, mud puppy, Ambystoma mexicanum',\n",
       " 'box turtle, box tortoise',\n",
       " 'ostrich, Struthio camelus',\n",
       " 'macaw',\n",
       " 'tarantula',\n",
       " 'common iguana, iguana, Iguana iguana',\n",
       " 'sidewinder, horned rattlesnake, Crotalus cerastes',\n",
       " 'tree frog, tree-frog',\n",
       " 'toucan',\n",
       " 'hognose snake, puff adder, sand viper',\n",
       " 'great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias',\n",
       " 'leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea',\n",
       " 'American alligator, Alligator mississipiensis',\n",
       " 'coucal',\n",
       " 'European fire salamander, Salamandra salamandra',\n",
       " 'bald eagle, American eagle, Haliaeetus leucocephalus',\n",
       " 'drake',\n",
       " 'centipede']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pp.translateID(X) for X in trainingFolders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(pp.outputModelPath, 'CrazyNet67Epoch50ClassNewGen.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n01739381' 'n01739381' 'n01739381' ... 'n01784675' 'n01784675'\n",
      " 'n01784675']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29471383147853736,\n",
       " 0.4211049284578696,\n",
       " 0.5003974562798092,\n",
       " 0.5562400635930048,\n",
       " 0.6059220985691574]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = load_model((os.path.join(pp.outputModelPath, 'CrazyNet5Epoch50Class.h5')))\n",
    "\n",
    "h5db = h5py.File(h5file, 'r')\n",
    "pp.top5accuracies(model, h5db['x_val'][:], h5db['y_val'][:], encoder)\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-3a34c8424911>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-3a34c8424911>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "y_val = [k.decode('utf-8') for k in y_val]\n",
    "y_val = encoder.fit_transform(y_val)\n",
    "print(encoder.inverse_transform(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'n01440764', b'n01440764', b'n01440764', ..., b'n01518878',\n",
       "       b'n01518878', b'n01518878'], dtype='|S9')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output\\\\image-h5\\\\10-crazy.h5'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

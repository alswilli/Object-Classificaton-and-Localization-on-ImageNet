{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse images into input vector from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "dataPath = 'RealImageNet/ImageNetSubsample/Data/CLS-LOC'\n",
    "trainPath = os.path.join(dataPath, 'train')\n",
    "testPath = os.path.join(dataPath, 'test')\n",
    "validationPath = os.path.join(dataPath, 'val')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "# get training data\n",
    "x_train = []\n",
    "y_train = []\n",
    "trainingFolders = [x for x in os.listdir(trainPath)]\n",
    "\n",
    "lines = [line.rstrip('\\n').split() for line in open('RealImageNet/LOC_synset_mapping.txt')]\n",
    "# print(lines)\n",
    "wnids_to_words = {line[0]:' '.join(line[1:]) for line in lines }\n",
    "\n",
    "train_bboxes = {} #{image_name: list(bboxes)}\n",
    "for id in trainingFolders:\n",
    "    boxesPath = os.path.join(\"RealImageNet\", \"LOC_train_solution.csv\")\n",
    "    lines = [line.rstrip('\\n').split(',') for line in open(boxesPath)][1:]\n",
    "    for line in lines:\n",
    "        imageId = line[0]\n",
    "        predictionString = line[1]\n",
    "        split = predictionString.split()\n",
    "        train_bboxes[imageId] = []\n",
    "        for i in range(0, len(split), 5):\n",
    "            box = split[i:i+5]\n",
    "            train_bboxes[imageId].append(box)\n",
    "\n",
    "for imageName in train_bboxes.keys():\n",
    "    imageLabel = imageName.split('_')[0]\n",
    "    imagePath = os.path.join(trainPath, imageLabel, imageName + \".JPEG\") #folder name\n",
    "    \n",
    "    if os.path.exists(imagePath):\n",
    "        img = image.load_img(imagePath, target_size=(224, 224)) #pil format\n",
    "        x = image.img_to_array(img) \n",
    "#         x = np.expand_dims(x, axis=0) # making a numpy array (surrounds with another lis)\n",
    "#         x_train.append(x/255.)\n",
    "        for box in train_bboxes[imageName]:\n",
    "            x_train.append(x/255.)\n",
    "            idk = [imageLabel[1:]]\n",
    "            y_train.append(idk)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "# x_train = np.expand_dims(x_train, axis= 1)\n",
    "y_train = np.array(y_train, dtype = 'uint')\n",
    "# y_train = np.expand_dims(y_train, axis= 0)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_encoder = LabelBinarizer()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# print(transfomed_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(y_train_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get validation data\n",
    "\n",
    "validation_bboxes = {} #{image_name: list(bboxes)}\n",
    "# for id in trainingFolders:\n",
    "valBoxesPath = os.path.join(\"RealImageNet\", \"LOC_val_solution.csv\")\n",
    "lines = [line.rstrip('\\n').split(',') for line in open(valBoxesPath)][1:]\n",
    "for line in lines:\n",
    "    imageId = line[0]\n",
    "    predictionString = line[1]\n",
    "    split = predictionString.split()\n",
    "    validation_bboxes[imageId] = []\n",
    "    for i in range(0, len(split), 5):\n",
    "        box = split[i:i+5]\n",
    "        validation_bboxes[imageId].append(box)\n",
    "\n",
    "for imageName in validation_bboxes.keys():\n",
    "    imagePath = os.path.join(validationPath, imageName + \".JPEG\")\n",
    "    if os.path.exists(imagePath):\n",
    "        img = image.load_img(imagePath, target_size=(224, 224)) #pil format\n",
    "        x = image.img_to_array(img)  \n",
    "\n",
    "\n",
    "# get test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up and train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import Sequential # How layers interact (x -> y)\n",
    "# from keras.layers import Dense      # Type of layer (what you feed your data into)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(units=256, activation=\"softmax\"))\n",
    "\n",
    "# # LATER: Specify input shape!!\n",
    "\n",
    "# #define metrics, loss function (maybe our own?), gradient descent\n",
    "# model.compile(loss = \"categorical_crossentropy\", metrics = [\"accuracy\"], optimizer = \"adam\")\n",
    "\n",
    "# # Train model\n",
    "model.fit(x_train, y_train, epochs = 1, verbose=1)\n",
    "\n",
    "# Validate\n",
    "\n",
    "# Evaluate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# LATER: Add the image net parsing here, then do for-loop\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "# img_path = 'elephant.jpg'\n",
    "# img = image.load_img(img_path, target_size=(224, 224)) # kil format based on pillow -> loads to certain size\n",
    "# x = image.img_to_array(img)                            \n",
    "# x = np.expand_dims(x, axis=0)                          # making a numpy array\n",
    "\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])\n",
    "# Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_train[1000:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strs = ['n0' + str(int(x)) for x in label_encoder.inverse_transform(pred[0])]\n",
    "outputs = [wnids_to_words[x] for x in strs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with other model for localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(img_height, img_width, img_channels))\n",
    "\n",
    "# The following identity layer is only needed so that subsequent lambda layers can be optional.\n",
    "x1 = Lambda(lambda z: z,\n",
    "            output_shape=(img_height, img_width, img_channels),\n",
    "            name='idendity_layer')(x)\n",
    "if not (subtract_mean is None):\n",
    "    x1 = Lambda(lambda z: z - np.array(subtract_mean),\n",
    "               output_shape=(img_height, img_width, img_channels),\n",
    "               name='input_mean_normalization')(x1)\n",
    "if not (divide_by_stddev is None):\n",
    "    x1 = Lambda(lambda z: z / np.array(divide_by_stddev),\n",
    "               output_shape=(img_height, img_width, img_channels),\n",
    "               name='input_stddev_normalization')(x1)\n",
    "if swap_channels and (img_channels == 3):\n",
    "    x1 = Lambda(lambda z: z[...,::-1],\n",
    "               output_shape=(img_height, img_width, img_channels),\n",
    "               name='input_channel_swap')(x1)\n",
    "\n",
    "conv1 = Conv2D(32, (5, 5), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv1')(x1)\n",
    "conv1 = BatchNormalization(axis=3, momentum=0.99, name='bn1')(conv1) # Tensorflow uses filter format [filter_height, filter_width, in_channels, out_channels], hence axis = 3\n",
    "conv1 = ELU(name='elu1')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2), name='pool1')(conv1)\n",
    "\n",
    "conv2 = Conv2D(48, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv2')(pool1)\n",
    "conv2 = BatchNormalization(axis=3, momentum=0.99, name='bn2')(conv2)\n",
    "conv2 = ELU(name='elu2')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2), name='pool2')(conv2)\n",
    "\n",
    "conv3 = Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv3')(pool2)\n",
    "conv3 = BatchNormalization(axis=3, momentum=0.99, name='bn3')(conv3)\n",
    "conv3 = ELU(name='elu3')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2), name='pool3')(conv3)\n",
    "\n",
    "conv4 = Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv4')(pool3)\n",
    "conv4 = BatchNormalization(axis=3, momentum=0.99, name='bn4')(conv4)\n",
    "conv4 = ELU(name='elu4')(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2), name='pool4')(conv4)\n",
    "\n",
    "conv5 = Conv2D(48, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv5')(pool4)\n",
    "conv5 = BatchNormalization(axis=3, momentum=0.99, name='bn5')(conv5)\n",
    "conv5 = ELU(name='elu5')(conv5)\n",
    "pool5 = MaxPooling2D(pool_size=(2, 2), name='pool5')(conv5)\n",
    "\n",
    "conv6 = Conv2D(48, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv6')(pool5)\n",
    "conv6 = BatchNormalization(axis=3, momentum=0.99, name='bn6')(conv6)\n",
    "conv6 = ELU(name='elu6')(conv6)\n",
    "pool6 = MaxPooling2D(pool_size=(2, 2), name='pool6')(conv6)\n",
    "\n",
    "conv7 = Conv2D(32, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv7')(pool6)\n",
    "conv7 = BatchNormalization(axis=3, momentum=0.99, name='bn7')(conv7)\n",
    "conv7 = ELU(name='elu7')(conv7)\n",
    "\n",
    "# The next part is to add the convolutional predictor layers on top of the base network\n",
    "# that we defined above. Note that I use the term \"base network\" differently than the paper does.\n",
    "# To me, the base network is everything that is not convolutional predictor layers or anchor\n",
    "# box layers. In this case we'll have four predictor layers, but of course you could\n",
    "# easily rewrite this into an arbitrarily deep base network and add an arbitrary number of\n",
    "# predictor layers on top of the base network by simply following the pattern shown here.\n",
    "\n",
    "# Build the convolutional predictor layers on top of conv layers 4, 5, 6, and 7.\n",
    "# We build two predictor layers on top of each of these layers: One for class prediction (classification), one for box coordinate prediction (localization)\n",
    "# We precidt `n_classes` confidence values for each box, hence the `classes` predictors have depth `n_boxes * n_classes`\n",
    "# We predict 4 box coordinates for each box, hence the `boxes` predictors have depth `n_boxes * 4`\n",
    "# Output shape of `classes`: `(batch, height, width, n_boxes * n_classes)`\n",
    "classes4 = Conv2D(n_boxes[0] * n_classes, (3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='classes4')(conv4)\n",
    "classes5 = Conv2D(n_boxes[1] * n_classes, (3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='classes5')(conv5)\n",
    "classes6 = Conv2D(n_boxes[2] * n_classes, (3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='classes6')(conv6)\n",
    "classes7 = Conv2D(n_boxes[3] * n_classes, (3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='classes7')(conv7)\n",
    "# Output shape of `boxes`: `(batch, height, width, n_boxes * 4)`\n",
    "boxes4 = Conv2D(n_boxes[0] * 4, (3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='boxes4')(conv4)\n",
    "boxes5 = Conv2D(n_boxes[1] * 4, (3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='boxes5')(conv5)\n",
    "boxes6 = Conv2D(n_boxes[2] * 4, (3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='boxes6')(conv6)\n",
    "boxes7 = Conv2D(n_boxes[3] * 4, (3, 3), strides=(1, 1), padding=\"valid\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='boxes7')(conv7)\n",
    "\n",
    "# Generate the anchor boxes\n",
    "# Output shape of `anchors`: `(batch, height, width, n_boxes, 8)`\n",
    "anchors4 = AnchorBoxes(img_height, img_width, this_scale=scales[0], next_scale=scales[1], aspect_ratios=aspect_ratios[0],\n",
    "                       two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[0], this_offsets=offsets[0],\n",
    "                       limit_boxes=limit_boxes, variances=variances, coords=coords, normalize_coords=normalize_coords, name='anchors4')(boxes4)\n",
    "anchors5 = AnchorBoxes(img_height, img_width, this_scale=scales[1], next_scale=scales[2], aspect_ratios=aspect_ratios[1],\n",
    "                       two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[1], this_offsets=offsets[1],\n",
    "                       limit_boxes=limit_boxes, variances=variances, coords=coords, normalize_coords=normalize_coords, name='anchors5')(boxes5)\n",
    "anchors6 = AnchorBoxes(img_height, img_width, this_scale=scales[2], next_scale=scales[3], aspect_ratios=aspect_ratios[2],\n",
    "                       two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[2], this_offsets=offsets[2],\n",
    "                       limit_boxes=limit_boxes, variances=variances, coords=coords, normalize_coords=normalize_coords, name='anchors6')(boxes6)\n",
    "anchors7 = AnchorBoxes(img_height, img_width, this_scale=scales[3], next_scale=scales[4], aspect_ratios=aspect_ratios[3],\n",
    "                       two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[3], this_offsets=offsets[3],\n",
    "                       limit_boxes=limit_boxes, variances=variances, coords=coords, normalize_coords=normalize_coords, name='anchors7')(boxes7)\n",
    "\n",
    "# Reshape the class predictions, yielding 3D tensors of shape `(batch, height * width * n_boxes, n_classes)`\n",
    "# We want the classes isolated in the last axis to perform softmax on them\n",
    "classes4_reshaped = Reshape((-1, n_classes), name='classes4_reshape')(classes4)\n",
    "classes5_reshaped = Reshape((-1, n_classes), name='classes5_reshape')(classes5)\n",
    "classes6_reshaped = Reshape((-1, n_classes), name='classes6_reshape')(classes6)\n",
    "classes7_reshaped = Reshape((-1, n_classes), name='classes7_reshape')(classes7)\n",
    "# Reshape the box coordinate predictions, yielding 3D tensors of shape `(batch, height * width * n_boxes, 4)`\n",
    "# We want the four box coordinates isolated in the last axis to compute the smooth L1 loss\n",
    "boxes4_reshaped = Reshape((-1, 4), name='boxes4_reshape')(boxes4)\n",
    "boxes5_reshaped = Reshape((-1, 4), name='boxes5_reshape')(boxes5)\n",
    "boxes6_reshaped = Reshape((-1, 4), name='boxes6_reshape')(boxes6)\n",
    "boxes7_reshaped = Reshape((-1, 4), name='boxes7_reshape')(boxes7)\n",
    "# Reshape the anchor box tensors, yielding 3D tensors of shape `(batch, height * width * n_boxes, 8)`\n",
    "anchors4_reshaped = Reshape((-1, 8), name='anchors4_reshape')(anchors4)\n",
    "anchors5_reshaped = Reshape((-1, 8), name='anchors5_reshape')(anchors5)\n",
    "anchors6_reshaped = Reshape((-1, 8), name='anchors6_reshape')(anchors6)\n",
    "anchors7_reshaped = Reshape((-1, 8), name='anchors7_reshape')(anchors7)\n",
    "\n",
    "# Concatenate the predictions from the different layers and the assosciated anchor box tensors\n",
    "# Axis 0 (batch) and axis 2 (n_classes or 4, respectively) are identical for all layer predictions,\n",
    "# so we want to concatenate along axis 1\n",
    "# Output shape of `classes_merged`: (batch, n_boxes_total, n_classes)\n",
    "classes_concat = Concatenate(axis=1, name='classes_concat')([classes4_reshaped,\n",
    "                                                             classes5_reshaped,\n",
    "                                                             classes6_reshaped,\n",
    "                                                             classes7_reshaped])\n",
    "\n",
    "# Output shape of `boxes_final`: (batch, n_boxes_total, 4)\n",
    "boxes_concat = Concatenate(axis=1, name='boxes_concat')([boxes4_reshaped,\n",
    "                                                         boxes5_reshaped,\n",
    "                                                         boxes6_reshaped,\n",
    "                                                         boxes7_reshaped])\n",
    "\n",
    "# Output shape of `anchors_final`: (batch, n_boxes_total, 8)\n",
    "anchors_concat = Concatenate(axis=1, name='anchors_concat')([anchors4_reshaped,\n",
    "                                                             anchors5_reshaped,\n",
    "                                                             anchors6_reshaped,\n",
    "                                                             anchors7_reshaped])\n",
    "\n",
    "# The box coordinate predictions will go into the loss function just the way they are,\n",
    "# but for the class predictions, we'll apply a softmax activation layer first\n",
    "classes_softmax = Activation('softmax', name='classes_softmax')(classes_concat)\n",
    "\n",
    "# Concatenate the class and box coordinate predictions and the anchors to one large predictions tensor\n",
    "# Output shape of `predictions`: (batch, n_boxes_total, n_classes + 4 + 8)\n",
    "predictions = Concatenate(axis=2, name='predictions')([classes_softmax, boxes_concat, anchors_concat])\n",
    "\n",
    "model = Model(inputs=x, outputs=predictions)\n",
    "\n",
    "if return_predictor_sizes:\n",
    "    # Get the spatial dimensions (height, width) of the convolutional predictor layers, we need them to generate the default boxes\n",
    "    # The spatial dimensions are the same for the `classes` and `boxes` predictors\n",
    "    predictor_sizes = np.array([classes4._keras_shape[1:3],\n",
    "                                classes5._keras_shape[1:3],\n",
    "                                classes6._keras_shape[1:3],\n",
    "                                classes7._keras_shape[1:3]])\n",
    "    return model, predictor_sizes\n",
    "else:\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies:\n",
    "\n",
    "The code is in python3. \n",
    "\n",
    "You'll need to install the following libraries before being able to run. There may additional libraries you need to install to run.\n",
    "\n",
    "Tensorflow (using 1.5 because newer versions broken on mac for some reason)\n",
    "\n",
    "`pip3 install tensorflow==1.5`\n",
    "\n",
    "Keras\n",
    "\n",
    "`pip3 install keras`\n",
    "\n",
    "OpenCV\n",
    "\n",
    "`pip3 install opencv-python`\n",
    "\n",
    "ImageAI\n",
    "\n",
    "`pip3 install https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.2/imageai-2.0.2-py3-none-any.whl`\n",
    "\n",
    "Pillow, Scipy, numpy, matplotlib\n",
    "`pip3 install pillow scipy numpy matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 18:50:55) [MSC v.1915 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download TinyImageNet and Pre-trained YOLOv3 model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io, os\n",
    "import numpy as np\n",
    "\n",
    "if not os.path.isdir(os.path.join(os.getcwd(), 'tiny-imagenet-200')):\n",
    "    zip_file_url = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'\n",
    "    print(\"Downloading Tiny ImageNet 200...\")\n",
    "    r = requests.get(zip_file_url)\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    print(\"Extracting contents...\")\n",
    "    z.extractall()\n",
    "\n",
    "\n",
    "def download_file(url):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    # NOTE the stream=True parameter\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024): \n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "    return local_filename\n",
    "\n",
    "#Also download pretrained model file https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo.h5\n",
    "if not os.path.exists(os.path.join(os.getcwd(), 'yolo.h5')):\n",
    "    print(\"Downloading pretrained YoloV3 model file...\")\n",
    "    download_file('https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load bounding box information for each training image, organized by WordNet ID (wnid) \n",
    "\n",
    "This will be useful to parse information for specific images later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(os.getcwd(), 'tiny-imagenet-200', 'train')\n",
    "#get all the subdirectories from train/, \n",
    "training_wnids = [x for x in os.listdir(train_dir)]\n",
    "\n",
    "lines = [line.rstrip('\\n').split('\\t') for line in open('tiny-imagenet-200/words.txt')]\n",
    "wnids_to_words = {line[0]:line[1] for line in lines }\n",
    "\n",
    "train_bboxes = {} #{wnid: {image_name: bboxes}\n",
    "for id in training_wnids:\n",
    "    path = os.path.join(train_dir, id, id+\"_boxes.txt\")\n",
    "    lines = [line.rstrip('\\n').split('\\t') for line in open(path)]\n",
    "    train_bboxes[id] = { line[0]:np.array(line[1:], dtype=np.int) for line in lines }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goldfish, Carassius auratus'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnids_to_words[training_wnids[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained model using ImageAI and test on image\n",
    "\n",
    "Model is trained on full imagenet, so using it here on tiny imagenet doesn't make a lot of sense, but it's only for testing purposes. \n",
    "\n",
    "Take in an image and output to \"{testid}-test-out.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0750498dc930>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimageai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDetection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mObjectDetection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mexecution_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imageai\\Detection\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimageai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDetection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_retinanet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mresnet50_retinanet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimageai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDetection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_retinanet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_image_bgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread_image_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread_image_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresize_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimageai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDetection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_retinanet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdraw_box\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdraw_caption\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "test_id = 'n07920052'\n",
    "test_img_num = 1\n",
    "test_img_path = os.path.join(train_dir, test_id, 'images', test_id + '_' + str(test_img_num) + '.JPEG')\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath( os.path.join(execution_path , \"yolo.h5\"))\n",
    "detector.loadModel()\n",
    "detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , test_img_path), \n",
    "                                             output_image_path=os.path.join(execution_path , test_id + \"-\" + str(test_img_num) + \"-test-out.jpg\"), \n",
    "                                             minimum_percentage_probability=30)\n",
    "pred_bbox = None\n",
    "for eachObject in detections:\n",
    "    pred_bbox = eachObject[\"box_points\"]\n",
    "    print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n",
    "    print(\"--------------------------------\")\n",
    "    \n",
    "    \n",
    "truth_bbox = train_bboxes[test_id][os.path.basename(test_img_path)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate area overlap ratio of bounding box prediction vs. truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give tuples/lists in form (xmin, ymin, xmax, ymax)\n",
    "\n",
    "def overlap(a, b):  # returns None if rectangles don't intersect\n",
    "    \n",
    "    dx = min(a[2], b[2]) - max(a[0], b[0])\n",
    "    dy = min(a[3], b[3]) - max(a[1], b[1])\n",
    "    truth_area = (b[3]-b[1])*(b[2]-b[0])\n",
    "    pred_area = (a[3]-a[1])*(a[2]-a[0])\n",
    "#     print(truth_area)\n",
    "    if (dx>=0) and (dy>=0):\n",
    "        intersect = truth_area+pred_area-dx*dy\n",
    "        return dx*dy / intersect\n",
    "    \n",
    "\n",
    "    \n",
    "overlap(pred_bbox, truth_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.applications.resnet50 import ResNet50\n",
    "# from keras.preprocessing import image\n",
    "# from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "# import numpy as np\n",
    "\n",
    "# model = ResNet50(weights='imagenet')\n",
    "\n",
    "# img_path = 'elephant.jpg'\n",
    "# img = image.load_img(img_path, target_size=(224, 224))\n",
    "# x = image.img_to_array(img)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# x = preprocess_input(x)\n",
    "\n",
    "# preds = model.predict(x)\n",
    "# # decode the results into a list of tuples (class, description, probability)\n",
    "# # (one such list for each sample in the batch)\n",
    "# print('Predicted:', decode_predictions(preds, top=3)[0])\n",
    "# # Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse images into input vector from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "dataPath = 'RealImageNet/ImageNetSubsample/Data/CLS-LOC'\n",
    "trainPath = os.path.join(dataPath, 'train')\n",
    "testPath = os.path.join(dataPath, 'test')\n",
    "validationPath = os.path.join(dataPath, 'val')\n",
    "\n",
    "x_train, y_train = np.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "# get training data\n",
    "\n",
    "trainingFolders = [x for x in os.listdir(trainPath)]\n",
    "\n",
    "lines = [line.rstrip('\\n').split() for line in open('RealImageNet/LOC_synset_mapping.txt')]\n",
    "# print(lines)\n",
    "wnids_to_words = {line[0]:' '.join(line[1:]) for line in lines }\n",
    "\n",
    "train_bboxes = {} #{image_name: list(bboxes)}\n",
    "for id in trainingFolders:\n",
    "    boxesPath = os.path.join(\"RealImageNet\", \"LOC_train_solution.csv\")\n",
    "    lines = [line.rstrip('\\n').split(',') for line in open(boxesPath)][1:]\n",
    "    for line in lines:\n",
    "        imageId = line[0]\n",
    "        predictionString = line[1]\n",
    "        split = predictionString.split()\n",
    "        train_bboxes[imageId] = []\n",
    "        for i in range(0, len(split), 5):\n",
    "            box = split[i:i+5]\n",
    "            train_bboxes[imageId].append(box)\n",
    "\n",
    "for imageName in train_bboxes.keys():\n",
    "    imageLabel = imageName.split('_')[0]\n",
    "    imagePath = os.path.join(trainPath, imageLabel, imageName + \".JPEG\") #folder name\n",
    "    if os.path.exists(imagePath):\n",
    "        img = image.load_img(imagePath, target_size=(224, 224)) #pil format\n",
    "        x = image.img_to_array(img)  \n",
    "        x = np.expand_dims(x, axis=0) # making a numpy array (surrounds with another lis)\n",
    "        x_train.append(x/255.)\n",
    "        y_train.append(imageLabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get validation data\n",
    "\n",
    "validation_bboxes = {} #{image_name: list(bboxes)}\n",
    "# for id in trainingFolders:\n",
    "valBoxesPath = os.path.join(\"RealImageNet\", \"LOC_val_solution.csv\")\n",
    "lines = [line.rstrip('\\n').split(',') for line in open(valBoxesPath)][1:]\n",
    "for line in lines:\n",
    "    imageId = line[0]\n",
    "    predictionString = line[1]\n",
    "    split = predictionString.split()\n",
    "    validation_bboxes[imageId] = []\n",
    "    for i in range(0, len(split), 5):\n",
    "        box = split[i:i+5]\n",
    "        validation_bboxes[imageId].append(box)\n",
    "\n",
    "for imageName in validation_bboxes.keys():\n",
    "    imagePath = os.path.join(validationPath, imageName + \".JPEG\")\n",
    "    if os.path.exists(imagePath):\n",
    "        img = image.load_img(imagePath, target_size=(224, 224)) #pil format\n",
    "        x = image.img_to_array(img)  \n",
    "        print(x)\n",
    "        x = np.expand_dims(x, axis=0)                          # making a numpy array (surrounds with another lis)\n",
    "#         print(x)\n",
    "\n",
    "# get test data\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# LATER: Add the image net parsing here, then do for-loop\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "# img_path = 'elephant.jpg'\n",
    "# img = image.load_img(img_path, target_size=(224, 224)) # kil format based on pillow -> loads to certain size\n",
    "# x = image.img_to_array(img)                            \n",
    "# x = np.expand_dims(x, axis=0)                          # making a numpy array\n",
    "\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])\n",
    "# Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up and train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential # How layers interact (x -> y)\n",
    "# from keras.layers import Dense      # Type of layer (what you feed your data into)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(units=256, activation=\"softmax\"))\n",
    "\n",
    "# # LATER: Specify input shape!!\n",
    "\n",
    "# #define metrics, loss function (maybe our own?), gradient descent\n",
    "# model.compile(loss = \"categorical_crossentropy\", metrics = [\"accuracy\"], optimizer = \"adam\")\n",
    "\n",
    "# # Train model\n",
    "model.fit(x_train, y_train, epochs = 1)\n",
    "\n",
    "# Validate\n",
    "\n",
    "# Evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
